{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90221fd2",
   "metadata": {},
   "source": [
    "# Variational Shadow Quantum Learning\n",
    "\n",
    "The method of VSQL can be shown in the diagram:\n",
    "\n",
    "![](https://github.com/tzajack/Quantum-ML-Computing-Learning/blob/main/Variational%20Shadow%20Quantum%20Learning/fig1.png?raw=true)\n",
    "\n",
    "One can easily see that instead of using a unitary gate which has quantum gates on every qubit in the circuit, VSQL use a unitray gate with less number of qubits and move the unitray gate along all the qubits.\n",
    "\n",
    "One interesting analogy can be made with CNN. The unitary gate $U(\\theta)$ is the kernel in CNN. Number of qubit used in $U(\\theta)$ is the size of the kernel.\n",
    "\n",
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3222a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d944440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThinkPad\\AppData\\Roaming\\Python\\Python39\\site-packages\\urllib3\\util\\selectors.py:14: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import namedtuple, Mapping\n",
      "C:\\Users\\ThinkPad\\AppData\\Roaming\\Python\\Python39\\site-packages\\urllib3\\_collections.py:2: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Mapping, MutableMapping\n",
      "C:\\Users\\ThinkPad\\AppData\\Roaming\\Python\\Python39\\site-packages\\openfermion\\hamiltonians\\hartree_fock.py:11: DeprecationWarning: Please use `OptimizeResult` from the `scipy.optimize` namespace, the `scipy.optimize.optimize` namespace is deprecated.\n",
      "  from scipy.optimize.optimize import OptimizeResult\n",
      "C:\\Users\\ThinkPad\\AppData\\Roaming\\Python\\Python39\\site-packages\\paddle\\tensor\\creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "from paddle.vision.datasets import MNIST\n",
    "import paddle_quantum\n",
    "from paddle_quantum.ansatz import Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e83fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(n_train=1000, n_test=100):\n",
    "    # We use the MNIST provided by paddle\n",
    "    train_dataset = MNIST(mode='train')\n",
    "    test_dataset = MNIST(mode='test')\n",
    "    # Select data points from category 0 and 1\n",
    "    train_dataset = np.array([i for i in train_dataset if i[1][0] == 0 or i[1][0] == 1], dtype=object)\n",
    "    test_dataset = np.array([i for i in test_dataset if i[1][0] == 0 or i[1][0] == 1], dtype=object)\n",
    "    np.random.shuffle(train_dataset)\n",
    "    np.random.shuffle(test_dataset)\n",
    "    # Separate images and labels\n",
    "    train_images = train_dataset[:, 0][:n_train]\n",
    "    train_labels = train_dataset[:, 1][:n_train].astype('int64')\n",
    "    test_images = test_dataset[:, 0][:n_test]\n",
    "    test_labels = test_dataset[:, 1][:n_test].astype('int64')\n",
    "    # Normalize data and pad them with zeros\n",
    "    x_train = norm_img(train_images)\n",
    "    x_test = norm_img(test_images)\n",
    "    # Transform integer labels into one-hot vectors\n",
    "    train_targets = np.array(train_labels).reshape(-1)\n",
    "    y_train = paddle.to_tensor(np.eye(2)[train_targets])\n",
    "    test_targets = np.array(test_labels).reshape(-1)\n",
    "    y_test = paddle.to_tensor(np.eye(2)[test_targets])\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9ea64",
   "metadata": {},
   "source": [
    "The structure of $U(\\theta)$ is:\n",
    "![](https://qml.baidu.com/static/464ec9f483f300e02d4e45131f92a694/fcda8/vsql-fig-2-local.png)\n",
    "\n",
    "The construction is the same to the one in Quantum Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b4c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the shadow circuit U(theta)\n",
    "def U_theta(n, n_qsc, depth):\n",
    "    # Initialize the circuit\n",
    "    cir = Circuit(n)\n",
    "    # Add layers of rotation gates\n",
    "    for i in range(n_qsc):\n",
    "        cir.rx(qubits_idx=i)\n",
    "        cir.ry(qubits_idx=i)\n",
    "        cir.rx(qubits_idx=i)\n",
    "        \n",
    "    # Add D layers of Ry and CNOT after each pair\n",
    "    for repeat in range(1, depth + 1):\n",
    "        for i in range(n_qsc - 1):\n",
    "            cir.cnot([i, i + 1])\n",
    "        cir.cnot([n_qsc - 1, 0])\n",
    "        for i in range(n_qsc):\n",
    "            cir.ry(qubits_idx=i)\n",
    "\n",
    "    return cir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28333cc3",
   "metadata": {},
   "source": [
    "Before complete the sliding of $U(\\theta)$, first see how sublayers() works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe86854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Rx(0.239)----Ry(5.652)----Rx(0.521)--\n",
      "                                       \n",
      "--Rx(0.006)----Ry(5.197)----Rx(4.125)--\n",
      "                                       \n",
      "--Rx(5.493)----------------------------\n",
      "                                       \n",
      "---------------------------------------\n",
      "                                       \n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "tmpcir = Circuit(4)\n",
    "for i in range(2):\n",
    "    tmpcir.rx(qubits_idx=i)\n",
    "    tmpcir.ry(qubits_idx=i)\n",
    "    tmpcir.rx(qubits_idx=i)\n",
    "tmpcir.rx(qubits_idx=2)\n",
    "print(tmpcir)\n",
    "for sublayer in tmpcir.sublayers():\n",
    "    print(sublayer.qubits_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54755027",
   "metadata": {},
   "source": [
    "We can see that sublayers() is a iterable variable that scans every qubit of the circuit, if there is no gate on a certain qubit, it will ignore this qubit(the qubit is not deleted, we just do not count the gate on it).\n",
    "\n",
    "We can implment sliding by changing the qubits_idx of each sublayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d2e982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_circuit(cir, distance):\n",
    "    for sublayer in cir.sublayers():\n",
    "        qubits_idx = np.array(sublayer.qubits_idx)\n",
    "        qubits_idx = qubits_idx + distance\n",
    "        sublayer.qubits_idx = qubits_idx.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0de4f",
   "metadata": {},
   "source": [
    "Try to slide the tmpcir downwards to test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c649caaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "                                       \n",
      "--Rx(0.239)----Ry(5.652)----Rx(0.521)--\n",
      "                                       \n",
      "--Rx(0.006)----Ry(5.197)----Rx(4.125)--\n",
      "                                       \n",
      "--Rx(5.493)----------------------------\n",
      "                                       \n"
     ]
    }
   ],
   "source": [
    "slide_circuit(tmpcir,1)\n",
    "print(tmpcir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33de7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def observable(n_start, n_qsc):\n",
    "    pauli_str = ','.join('x' + str(i) for i in range(n_start, n_start + n_qsc))\n",
    "    hamiltonian = paddle_quantum.Hamiltonian([[1.0, pauli_str]])\n",
    "\n",
    "    return hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad8a93c",
   "metadata": {},
   "source": [
    "Noted that the network structure is different from the one in tutorial, here we try to use the approach of the paper\n",
    "\n",
    "[1] The paper use a $1$ dimension output linear layer and use a sigmoid map to the label.\n",
    "\n",
    "[2] The paper use MSE loss instead of cross-entropy loss in the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d85631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(paddle.nn.Layer):\n",
    "    def __init__(self,\n",
    "                 n, \n",
    "                 n_qsc, \n",
    "                 depth \n",
    "                ):\n",
    "        super(Net, self).__init__()\n",
    "        self.n = n\n",
    "        self.n_qsc = n_qsc\n",
    "        self.depth = depth\n",
    "        self.cir = U_theta(self.n, n_qsc=self.n_qsc, depth=self.depth)\n",
    "        self.fc = paddle.nn.Linear(n - n_qsc + 1, 1,\n",
    "                                   weight_attr=paddle.ParamAttr(initializer=paddle.nn.initializer.Normal()),\n",
    "                                   bias_attr=paddle.ParamAttr(initializer=paddle.nn.initializer.Normal()))\n",
    "\n",
    "\n",
    "    def forward(self, batch_in, label):\n",
    "        \n",
    "        dim = len(batch_in)\n",
    "        features = []\n",
    "        for state in batch_in:\n",
    "            _state = paddle_quantum.State(state)\n",
    "            f_i = []\n",
    "            for st in range(self.n - self.n_qsc + 1):\n",
    "                ob = observable(st, n_qsc=self.n_qsc)\n",
    "                \n",
    "                #Slide the circuit\n",
    "                slide_circuit(self.cir, 1 if st != 0 else 0)\n",
    "                expecval = paddle_quantum.loss.ExpecVal(ob)\n",
    "                out_state = self.cir(_state)\n",
    "                \n",
    "                #Calculate O_i for each slide\n",
    "                f_ij = expecval(out_state)\n",
    "                f_i.append(f_ij)\n",
    "                \n",
    "            # Slide back to the original position\n",
    "            slide_circuit(self.cir, -st)\n",
    "            f_i = paddle.concat(f_i)\n",
    "            features.append(f_i) \n",
    "        features = paddle.stack(features)\n",
    "        \n",
    "        #Feed O_i to fully connect NN\n",
    "        output = self.fc(features)\n",
    "        #Run Sigmoid to the linear layer [1]\n",
    "        output = F.sigmoid(output)\n",
    "       # print('output',output)\n",
    "        #print('label',label)\n",
    "        #MSE loss [2]\n",
    "        lb = paddle.to_tensor(label)\n",
    "        loss = paddle.mean((output - lb)**2) \n",
    "        \n",
    "        #Calculate accuracy\n",
    "        is_correct = 0\n",
    "        is_correct = (paddle.abs(output - lb) < 0.5).nonzero().shape[0]\n",
    "        acc = is_correct / dim\n",
    "\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44670de0",
   "metadata": {},
   "source": [
    "Normal train() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe3b4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(N, n_qsc, D, EPOCH, LR, BATCH, x_train,y_train,x_test,y_test):\n",
    "    N_train = len(x_train)\n",
    "    net = Net(N, n_qsc, depth=D)\n",
    "\n",
    "    opt = paddle.optimizer.Adam(learning_rate=LR, parameters=net.parameters())\n",
    "\n",
    "   \n",
    "    for ep in range(EPOCH):\n",
    "        for itr in range(N_train // BATCH):\n",
    "            l = itr*BATCH\n",
    "            r = min( (itr + 1) * BATCH , N_train )\n",
    "            loss, batch_acc = net(x_train[l:r],y_train[l:r])\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            opt.minimize(loss)\n",
    "            opt.clear_grad()\n",
    "            \n",
    "            \n",
    "        loss_useless, test_acc = net(x_test,y_test)\n",
    "        print(\"epoch:%3d\" % ep,  \n",
    "            \"  loss: %.4f\" % loss.numpy(),\n",
    "            \"  test acc: %.4f\" % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161c393",
   "metadata": {},
   "source": [
    "For convenience, the MNIST data takes too long to train, so we use the titanic data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51e5fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((418, 5), (418, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.fillna(train_data['Age'].mean(),inplace = True)\n",
    "train_label = train_data['Survived']\n",
    "train_data = train_data.drop(['Survived','PassengerId'],axis = 1)\n",
    "normdata=(train_data-train_data.mean())/train_data.std()\n",
    "trainX = normdata.to_numpy()\n",
    "trainY = train_label.to_numpy()\n",
    "trainY = trainY.reshape(-1,1)\n",
    "train_x = trainX\n",
    "train_y = trainY\n",
    "train_x.shape,train_y.shape\n",
    "\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.fillna(test_data['Age'].mean(),inplace = True)\n",
    "test_data.fillna(test_data['Fare'].mean(),inplace = True)\n",
    "test_label = test_data['Survived']\n",
    "test_data = test_data.drop('Survived',axis = 1)\n",
    "test_data = test_data.drop('PassengerId',axis = 1)\n",
    "\n",
    "normdata=(test_data-test_data.mean())/test_data.std()\n",
    "testX = normdata.to_numpy()\n",
    "testY = test_label.to_numpy()\n",
    "testY = testY.reshape(-1,1)\n",
    "test_x = testX\n",
    "test_y = testY\n",
    "test_x.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f7c82f",
   "metadata": {},
   "source": [
    "Encode the data with amplitude encoding first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b13c40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle_quantum.dataset import *\n",
    "\n",
    "N=5\n",
    "n_qsc=3\n",
    "D=1\n",
    "EPOCH=3\n",
    "LR=0.1\n",
    "BATCH=64\n",
    "encoding = 'amplitude_encoding'\n",
    "quantum_train_x= SimpleDataset(5).encode(train_x, encoding, N)\n",
    "quantum_test_x= SimpleDataset(5).encode(test_x, encoding, N)\n",
    "quantum_train_x = paddle.to_tensor(quantum_train_x)\n",
    "quantum_test_x = paddle.to_tensor(quantum_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea734e0",
   "metadata": {},
   "source": [
    "Train the model and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9764e0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0   loss: 0.2412   test acc: 0.6196\n",
      "epoch:  1   loss: 0.2204   test acc: 0.6411\n",
      "epoch:  2   loss: 0.2075   test acc: 0.6388\n",
      "time used: 209.0915026664734\n"
     ]
    }
   ],
   "source": [
    "time_st = time.time()\n",
    "train(N, n_qsc, D, EPOCH, LR, BATCH, quantum_train_x, train_y, quantum_test_x, test_y)\n",
    "print(\"time used:\", time.time() - time_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eddb47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
